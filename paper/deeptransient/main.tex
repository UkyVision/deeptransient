\documentclass{article}
\usepackage{spconf,amsmath,graphicx}

\usepackage[breaklinks=true,colorlinks,bookmarks=false]{hyperref}

\newcommand{\todo}[1]{\textcolor{red}{todo: {\em #1}}}
\newcommand{\figref}[1]{Figure~\ref{fig:#1}}
\newcommand{\tblref}[1]{Table~\ref{tbl:#1}}


\title{Deep Methods for Estimating Transient Scene Properties}


\name{Ryan Baltenberger, Connor Greenwell, Scott Workman, Nathan Jacobs}
\address{ 
  Department of Computer Science \\ 
  University of Kentucky \\
  {\tt\small \{rbalten, connor, scott, jacobs\}@cs.uky.edu}
}


\begin{document}

\maketitle

\begin{abstract}

We propose to use deep convolutional neural networks to estimate the
transient attributes of a scene from a single image. Such networks
have been used to achieve state-of-the-art results for a wide range of
vision problems, from object detection to scene classification, but
have not been used for such attributes. Transient scene attributes
describe both the objective conditions, such as the weather, time of
day, and the season, and subjective properties, such whether or not
the scene is busy, of a scene. We compare several methods for
pre-training an existing network architecture and obtain
state-of-the-art results on two benchmark datasets.  We also show how
such networks may be used in several different applications.

\end{abstract}

\begin{keywords}
transient attributes, convolutional neural networks, deep learning
\end{keywords}

\begin{figure}[t!]
	\centering
		\includegraphics[width=0.5\textwidth]{figs/bars.pdf}

		\caption{An example image from the Transient Attributes Dataset with the ground truth labels
						 (red) and our network's predicted labels (blue).
             \todo{fig:sort is used as a label twice}}
             
             % \label{fig:sort}
\end{figure}

\section{Introduction}

\todo{later}

Deep learning has been used to obtain state of the art results in
problems ranging from object classification, object detection, and
scene classification.  Training and evaluating convolutional neural
networks has become faster and easier with new deep learning
frameworks and modern computational cababilities.  

% general intro to the problem and why it is important
% what do we propose to do? 
Outdoor scenes experience a multitude of lighting and weather conditions
everyday.  The scene can change from dark and rainy to sunny and clear 
skys in a matter of hours.  These fleeting, or transient, attributes of
a scene help create the dynamicism of the natural world.  Understanding 
and recognizing these transient attributes can help us analyze outdoor
scenes. We propose a method for predicting transient attributes on images 
using deep convolutional neural networks.  These networks achieve better 
predictions for most of the attributes and predict the attributes
faster than the methods proposed by Laffont~\cite{Laffont14} et al.

We propose a method for classifying images in the two class weather 
dataset using deep convolutional neural networks.  These networks 
achieves state of the art classification results on the dataset
constructed by Lu~\cite{lutwoclass} et al.
% how do we evaluate this?

We evaluate the proposed method on several benchmarks.  The first 
benchmark is the Transient Attributes Dataset~\cite{Laffont14}.  This 
is the standard benchmark dataset for transient attributes in outdoor
scenes.  We evaluate the proposed method on the holdout split, the 
most difficult split, in the dataset.  

% what we can do now that we have this?

% key contributions: repeat what was said above in bullet point form
The key contributions of this work are:
\begin{itemize}

  \item We compare several deep learning network architectures for
    		predicting transient attributes of in an outdoor scene.

	\item We achieve overall better predictions on the Transient Attributes
				benchmark dataset and the Two Class Weather Classification 
				benchmark dataset.

	\item We propose a method for automatically labeling and tagging images
				from outdoor webcam images for easier searching of webcam databases.

  %\item state-of-the-art results on two benchmark datasets (transient
  %  attributes and two class weather)

  %\item something with running it on webcam data?

\end{itemize}

\subsection{Related Work}

\todo{Write me}

Previous approaches to this problem include (some general description
of previous approaches and how they compare to what we propose).

List of related papers:
\begin{itemize}

	\item Laffont~\cite{Laffont14} et al. was the first to propose the 40
		transient attributes and created the Transient Attributes Dataset.
		Each attribute is given a value from 0 to 1 based on much a scene
		has that attribute. 	They used SVMs, logistic regression, and SVRs 
		to predict the attributes.  They use mean squared error and average 
		precision to compare their methods.

	\item Lu~\cite{lutwoclass} et al. classified images into one of two 
		classes, either sunny or cloudy.  They created the Two Class 
		Weather Classification Dataset.  They use learning and classification
		with their weather cues to classify the images. 

\end{itemize}


\subsection{Background}

Deep convolutional neural networks (CNNs) have been used extensively
in recent years to obtain state-of-the-art results on a wide variety
of computer vision problems.  In this work, we focus on a particular
CNN architecture, often called ``AlexNet'', introduced by Alex
Krizhevsky et al.~\cite{caffenetnips12} for single-image object
classification. This network has eight layers with trainable
parameters: five convolutional layers (each connected, in a
feed-forward manner with pooling and dropout layers between each
convolutional layer) and three fully connected layers. Essentially,
the convolutional layers extract features from across the image and
the fully connected layers combine these features to obtain a score
for each possible class. The final classification decision is obtained
by choosing the class with the highest output score.

While this network architecture was originally developed for
single-image object classification, it has been shown to be adaptable
to other problem domains. If the new problem involves multi-class
classification, all that is needed is to modify the final fully
connected layer to have the correct number of output classes. Then the
network weights can be `fine-tuned' by running iterations of stocastic
gradient descent on the training data for the new problem.  The key is
to start the optimization with random weights for the new final layer
and weights from an already trained network, for example using the
weights from the original AlexNet~\cite{caffenetnips12}, as an initial
condition. This approach was used in \todo{CITE}. If there is a large
amount of training data available for the new domain, it is also
possible to train the network from scratch by randomly initializing
all weights~\cite{zhou2014places}.  If the new problem domain is
regression, not classification, then the only change that is necessary
is to change the network loss function, perhaps replacing the SOFT-MAX
loss with an $L_2$ loss.

\section{Deep Networks for Estimating Transient Attributes}

We propose to use deep convolutional neural networks to classify
transient scene attributes. We develop networks for two single-image
problems: the classification problem of estimating whether it is sunny
or cloudy (CloudyNet) and a collection of regression problems that
represent the degree to which a large number of transient attribute
describe the scene (TransientNet).  For each of these problems, we
use three different networks as starting conditions for optimization,
resulting in a total of six networks.  For both problems, we use the
``AlexNet'' CNN architecture, described in the previous section.  The
remainder of this section describes how we estimate network weights
for each of these networks.

\textbf{CloudyNet:} For the problem of classifying whether an image is
sunny or cloudy, we use the data provided by Lu~\cite{lutwoclass} et
al.\ to train our network, which we call CloudyNet.  We follow their
protocol for training and testing: each list of sunny/cloudy images
was randomly shuffled and the first 80\% of each list was chosen as
the training data and the last 20\% was chosen as testing data.  The
only modification to the network architecture that was required was
dropping unnecessary output nodes from the final fully connected layer
(in the end we have two output nodes).

\textbf{TransientNet:} In addition, we train a network for the more
challenging problem of estimating a broad range of attributes proposed
by Laffont~\cite{Laffont14}.  In this problem, there are 40 transient
attributes (see Figure~\ref{figure_label} for the full list of
attributes), each of which is assigned a value between zero and one
for an image. We use the training set defined by
Laffont~\cite{Laffont14} in which the images from 81 webcams are used
for training and images from a distinct set of 20 webcams is used for
testing.  The only modification of the network architecture that was
required was changing the final fully connected layer to have 40
nodes, one for each transient attribute, and changing the loss
function to \todo{XX}. 

\todo{not sure if we still need this\dots Data from webcams in the
training set does not appear in the testing set using the holdout
split.  This is contrary to the random train/test split.  We finetuned
the last layer of each of the networks using the holdout split in the
transient attributes dataset.}

We trained both of these networks using three different initial
conditions resulting in six distinct sets of network weights. The
first set of initial conditions are taken from a network that was was
trained for scene classification on 1.2 million images from the
ImageNet ILSVRC-2012 challenge~\cite{ILSVRCarxiv14}.  We call the
networks that result from this fine-tuning process CloudyNet(I) and
TransientNet(I).  The second set of initial conditions were taken from
a network~\cite{zhou2014places} was trained for scene classification
on 2.5 million images with labels in 205 categories from the Places
Database~\cite{zhou2014places}. We call the resulting networks
CloudyNet(P) and TransientNet(P).  The final set of initial conditions
were taken from a network that was trained~\cite{zhou2014places} for
both object and scene classification.  This hybrid network was trained
on a combination of the Places Database~\cite{zhou2014places} and
images from the training data of ILSVRC-2012
challenge~\cite{ILSVRCarxiv14}.  The full training set contained 205
scene categories from the Places Database and 978 object categories
from ILSVRC-2012 totaling about 3.6 million images.  We call the
resulting networks CloudyNet(H) and TransientNet(H).

\textbf{Implementation Details:} We train each networks using the
Caffe~\cite{caffe14} deep learning software framework, the Caffenet
reference network architecture, and pre-trained networks from the
Caffe Model Zoo\footnote{\url{CITE}}.  In the interest of reproducible
research, the full network optimization definition, the final network
weights, and the output from our methods will be made available online
for all six networks.

\section{Evaluation}

\subsection{Two-Class Weather Classification Dataset}
\todo{Expand a bit more on the dataset}
\indent

We used the dataset created by Lu~\cite{lutwoclass} et al. to train our networks
for two class weather classification.  The dataset contains images collected from
the SUN Database~\cite{xiaoSUN}, the LabelMe Database~\cite{russell2008labelme}, and
Flickr. The dataset contains 5000 sunny and 5000 cloudy images. Flickr images were 
collected manually by ``helpers'' unaware of the purpose or methods of
Lu et al. The dataset was then pruned for images with similar
histograms, and finally pruned by another round of helpers to narrow
the dataset to 10,000 images. 

\subsection{Transient Attributes Dataset}
\indent

We used the dataset created by Laffont~\cite{Laffont14} et al. to train our 
networks for transient attribute prediction. The dataset contains images from 
outdoor webcams in the Archive of Many Outdoor Scenes~\cite{jacobs07amos} and 
the Webcam Clip Art Dataset~\cite{lalondesig09}.  The webcams span a wide range 
of outdoor scenes,from urban regions to wooded, mountainous regions. Each webcam 
has 60-120 representative images that feature variations in weather, lighting 
conditions, etc.  The images are high resolution and are aligned to a reference 
frame through a homography warp with manually specified correspondences.  The 
final dataset consists of 8571 images from 101 webcams.

\subsection{Network Evaluation}
\indent

\tblref{twoclass} shows the normalized accuracies of our networks compared to 
the method proposed by Lu~\cite{lutwoclass} et al.  The normalized accuracy was
calculated by $ \max\{((a - 0.5) / 0.5), 0\} $, where $a$ is the traditionally
obtained accuracy. All three of the networks outperform the state of the art for
two class weather classification with CloudyNet-P predicting the most accurately.

\figref{sort} shows the average errors from TransientNet-S for each attribute
in a sorted graph.  The attributes where TransientNet-S performed best are towards
the bottom of the graph and the attributes where TransientNet-S performed
worst are on the top of the graph. \figref{relerr} and \figref{compare} 
compare this performance to the performance of Laffont et al.

\figref{compare} shows the average errors from TransientNet-S, TransientNet-P, 
TransientNet-H and Laffont et al. for each attribute in the dataset.  The green bars 
represent the average errors from Laffont et al., the blue bars represent the average 
errors from TransientNet-S, the red bars represent the average errors from TransientNet-P, 
and the yellow bars represent the error from TransientNet-H. TransientNet-S performs best on 
more than half of the attributes and is the best performing CNN that we trained.  
Transient has the lowest overall average error as shown in \tblref{transient}.  TransientNet-P
and TransientNet-H have similar performance, mostly due to them being pretrained on similar 
sets of data.

\figref{relerr} shows the relative error between our method using TransientNet-S
and the method presented in~\cite{Laffont14}.  The average relative error 
for each attribute using the method in~\cite{Laffont14} was subtracted from
the average relative error using TransientNet-S.  A negative value means TransientNet-S
had a smaller error and a positive value means~\cite{Laffont14} had a smaller
error.  For example, the difference between the two methods on the attribute
night was around 3.2 percentage points, with TransientNet-S having the smaller 
error.

 
%Suggested plots:
%\begin{itemize}
%
%  \item summary results you have already shown
%
%  \item example good results, and plausible bad results
%
%\end{itemize}

\begin{table}[t]
	\centering
	\begin{tabular}{ | l | c | }
		\hline
			Method & Normalized Accuracy \\ \hline
			Lu et al.~\cite{lutwoclass}& 53.1\% \\ \hline
			CloudyNet-S & 81.8\% \\ \hline
			CloudyNet-P & \textbf{84.7\%} \\ \hline
			CloudyNet-H & 83.1\% \\ 
		\hline
	\end{tabular}
	\caption{Two Class Weather Classification Accuracy}
	\label{tbl:twoclass}
\end{table}

\begin{figure}[t]
	\centering
		\includegraphics[width=0.5\textwidth]{figs/sorted_err_cmr.pdf}
		\caption{This shows the average errors in TransientNet-S's predictions on the 
						 testing set sorted from largest to smallest.  The attributes at 
						 the top of the plot have the highest average error.}
		\label{fig:sort}
\end{figure}

\begin{figure}[t]
	\centering
		\includegraphics[width=0.5\textwidth]{figs/rel_err_cmr.pdf}
		\caption{This shows the relative errors of TransientNet-S against the method 
						 proposed by Laffont et al. for each attribute.  Attributes with a 
						 negative average error are attributes that are predicting more 
						 accurately by our method.}
		\label{fig:relerr}
\end{figure}

\begin{figure*}[t]
	\centering
		\includegraphics[width=1.0\textwidth]{figs/avg_err_compare_cmr.pdf}
		\caption{This shows the average errors for each attribute from proposed method
						 by Laffont et al., TransientNet-S, TransientNet-P, and TransientNet-H.  
             TransientNet-S has the lowest average error for most of the attributes.}
		\label{fig:compare}
\end{figure*}

\begin{table}[t]
	\centering
	\begin{tabular}{ | l | c | }
		\hline
			Method & Average Error \\ \hline
			Laffont et al.~\cite{Laffont14}& 8.48\% \\ \hline
			TransientNet-S & \textbf{7.65\%} \\ \hline
			TransientNet-P & 8.02\% \\ \hline
			TransientNet-H & 8.13\% \\ 
		\hline
	\end{tabular}
	\caption{Two Class Weather Classification Accuracy}
	\label{tbl:transient}
\end{table}

\section{Applications}
\todo{Think of more applications, expand on current one}
\subsection{Automatic Webcam Image Labeling}

\begin{itemize}

	\item Automatically label saved images from webcams
	\item Tag each image individually and be able to search for times from
			  webcam that had or did not have a certain attribute
	\item Tag frequent attributes for webcams (that aren't day/night)
	\item Makes AMOS or other webcam/image archives more searchable

\end{itemize}

% need another subsection

\section{Conclusions}
\todo{write me}

We evaluated the use of deep convolutional neural networks for predicting
transient attributes and classifying images in two class weather 
classification.  These networks achieve state of the art results on two
benchmark datasets.  The networks are simple to train and predict 
quickly.  The networks can quickly be retrained on additional datasets
and restructured.


\bibliographystyle{IEEEbib}
\bibliography{refs}

\end{document}

%\subsection{Deep Network Visualization}

%\todo{pictures of what the network looks like\dots highlighting how it
%is different from those trained for other purposes... probably
%focusing on the one or two that work the best}

