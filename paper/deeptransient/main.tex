\documentclass{article}
\usepackage{spconf,amsmath,graphicx}

\usepackage[breaklinks=true,colorlinks,bookmarks=false]{hyperref}

\newcommand{\todo}[1]{\textcolor{red}{todo: {\em #1}}}
\newcommand{\figref}[1]{Figure~\ref{fig:#1}}
\newcommand{\tblref}[1]{Table~\ref{tbl:#1}}

% Title.
% ------
\title{Deep Methods for Estimating Transient Scene Properties}
%
% Single address.
% ---------------
\name{}
\address{University of Kentucky}
%
% For example:
% ------------
%\address{School\\
%	Department\\
%	Address}
%
% Two addresses (uncomment and modify for two-address case).
% ----------------------------------------------------------
%\twoauthors
%  {A. Author-one, B. Author-two\sthanks{Thanks to XYZ agency for funding.}}
%	{School A-B\\
%	Department A-B\\
%	Address A-B}
%  {C. Author-three, D. Author-four\sthanks{The fourth author performed the work
%	while at ...}}
%	{School C-D\\
%	Department C-D\\
%	Address C-D}
%
\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}
	
	Deep learning has been used to obtain state of the art results in
  problems ranging from object classification, object detection, and
  scene classification.  Training and evaluating convolutional neural
	networks has become faster and easier with new deep learning 
	frameworks and modern computational cababilities.  We evaluate the 
	use of deep learning to predict subtle visual scene aspects, such as
	the lighting, the season, and subjective scene properties. These
	properties, or transient attributes, can be used to predict the 
	state of the scene from a single image.  We evaluate our networks
	on benchmark datasets against the state of the art method for 
	predicting these attributes and achieve state of the art results for 
	predicting attributes and classifying scenes.

\end{abstract}
%
\begin{keywords}
	deep learning, transient attributes
\end{keywords}

\begin{figure}[t!]
	\centering
		\includegraphics[width=0.5\textwidth]{figs/bars.pdf}
		\caption{An example image from the Transient Attributes Dataset with the ground truth labels
						 (red) and our network's predicted labels (blue).}\label{fig:sort}
\end{figure}

\section{Introduction}
\todo{Write me}\newline\indent
% general intro to the problem and why it is important
% what do we propose to do? 
Outdoor scenes experience a multitude of lighting and weather conditions
everyday.  The scene can change from dark and rainy to sunny and clear 
skys in a matter of hours.  These fleeting, or transient, attributes of
a scene help create the dynamicism of the natural world.  Understanding 
and recognizing these transient attributes can help us analyze outdoor
scenes. We propose a method for predicting transient attributes on images 
using deep convolutional neural networks.  These networks achieve better 
predictions for most of the attributes and predict the attributes
faster than the methods proposed by Laffont\cite{Laffont14} et al.

We propose a method for classifying images in the two class weather 
dataset using deep convolutional neural networks.  These networks 
achieves state of the art classification results on the dataset
constructed by Lu\cite{lutwoclass} et al.
% how do we evaluate this?

We evaluate the proposed method on several benchmarks.  The first 
benchmark is the Transient Attributes Dataset\cite{Laffont14}.  This 
is the standard benchmark dataset for transient attributes in outdoor
scenes.  We evaluate the proposed method on the holdout split, the 
most difficult split, in the dataset.  

% what we can do now that we have this?

% key contributions: repeat what was said above in bullet point form
The key contributions of this work are:
\begin{itemize}

  \item We compare several deep learning network architectures for
    		predicting transient attributes of in an outdoor scene.

	\item We achieve overall better predictions on the Transient Attributes
				benchmark dataset and the Two Class Weather Classification 
				benchmark dataset.

	\item We propose a method for automatically labeling and tagging images
				from outdoor webcam images for easier searching of webcam databases.

  %\item state-of-the-art results on two benchmark datasets (transient
  %  attributes and two class weather)

  %\item something with running it on webcam data?

\end{itemize}

\subsection{Related Work}

\todo{Write me}

Previous approaches to this problem include (some general description
of previous approaches and how they compare to what we propose).

List of related papers:
\begin{itemize}

	\item Laffont\cite{Laffont14} et al. was the first to propose the 40
		transient attributes and created the Transient Attributes Dataset.
		Each attribute is given a value from 0 to 1 based on much a scene
		has that attribute. 	They used SVMs, logistic regression, and SVRs 
		to predict the attributes.  They use mean squared error and average 
		precision to compare their methods.

	\item Lu\cite{lutwoclass} et al. classified images into one of two 
		classes, either sunny or cloudy.  They created the Two Class 
		Weather Classification Dataset.  They use learning and classification
		with their weather cues to classify the images. 

\end{itemize}

\section{Estimating Transient Attributes Using CNNs}

\subsection{Description of how we train ours}
\indent

\textbf{CloudyNet:} To train our networks, we use the Caffe\cite{caffe14} 
deep learning framework. We finetuned the last layer of each network architecture
for the two class weather classification as well.  The train/test split for this dataset
was randomly chosen.  Each list of sunny/cloudy images was randomly shuffled and the 
first 80\% of each list was chosen as the training data and the last 20\% was chosen
as testing data.  This is similar to the approach used by Lu\cite{lutwoclass} et al.

\textbf{TransientNet:} For transient attributes, we finetuned the last layer of each
of the networks using the holdout split in the transient attributes dataset.  This 
train/test split uses the data from 81 webcams for training and the data from 20 separate 
webcams for testing.  Data from webcams in the training set does not
appear in the testing set using the holdout split.  This is contrary to 
the random train/test split.  

\subsection{Recap of CNNs}
\indent

\textbf{Caffenet:} Caffenet is the reference network provided with 
Caffe\cite{caffe14}.  It was trained on 1.2 million images from the 
ILSVRC-2012\cite{ILSVRCarxiv14} challenge and is based on the architecture from 
the NIPS 2012 paper by Krizhevsky\cite{caffenetnips12} et al.  This network has 
8 learned layers, five convolutional layers and three fully-connected layers.  
It was trained on parts of the ImageNet dataset used in the 
ILSVRC-2010\cite{ILSVRCarxiv14} challenge.  This network was originally trained 
for object classification, but works well for other problems. For our application, 
we finetuned the final layer of Caffenet and changed the output of the final 
layer to be 40 (one output for each attribute).

\textbf{Places} The Places205-CNN architecture is the Caffenet network retrained on 
the Places Database\cite{zhou2014places}.  The Places205-CNN was trained on 2.5
million randomly selected images with labels in 205 categories from the Places 
Database.  We fine-tuned the final layer of Places205-CNN using the weights from the
pretrained network model provided by Zhou\cite{zhou2014places} et al.

\textbf{Hybrid:} The Hybrid-CNN architecture is the Caffenet network retrained on
a combination of the Places Database\cite{zhou2014places} and images from the 
training data of ILSVRC-2012\cite{ILSVRCarxiv14} challenge.  The full training set
contained 205 scene categories from the Places Database and 978 object categories
from ILSVRC-2012 totaling about 3.6 million images.  We fine-tuned the last 
layer of Hybrid-CNN using the weights from the pretrained network model provided by 
Zhou\cite{zhou2014places} et al.


%\subsection{Deep Network Visualization}

%\todo{pictures of what the network looks like\dots highlighting how it
%is different from those trained for other purposes... probably
%focusing on the one or two that work the best}

\section{Evaluation}

\subsection{Two-Class Weather Classification Dataset}
\todo{Expand a bit more on the dataset}
\indent

We used the dataset created by Lu\cite{lutwoclass} et al. to train our networks
for two class weather classification.  The dataset contains images collected from
the SUN Database\cite{xiaoSUN}, the LabelMe Database\cite{russell2008labelme}, and
Flickr. The dataset contains 5000 sunny and 5000 cloudy images. Flickr images were 
collected manually by ``helpers'' unaware of the purpose or methods of
Lu et al. The dataset was then pruned for images with similar
histograms, and finally pruned by another round of helpers to narrow
the dataset to 10,000 images. 

\subsection{Transient Attributes Dataset}
\indent

We used the dataset created by Laffont\cite{Laffont14} et al. to train our 
networks for transient attribute prediction. The dataset contains images from 
outdoor webcams in the Archive of Many Outdoor Scenes\cite{jacobs07amos} and 
the Webcam Clip Art Dataset\cite{lalondesig09}.  The webcams span a wide range 
of outdoor scenes,from urban regions to wooded, mountainous regions. Each webcam 
has 60-120 representative images that feature variations in weather, lighting 
conditions, etc.  The images are high resolution and are aligned to a reference 
frame through a homography warp with manually specified correspondences.  The 
final dataset consists of 8571 images from 101 webcams.

\subsection{Network Evaluation}
\indent

\tblref{twoclass} shows the normalized accuracies of our networks compared to 
the method proposed by Lu\cite{lutwoclass} et al.  The normalized accuracy was
calculated by $ \max\{((a - 0.5) / 0.5), 0\} $, where $a$ is the traditionally
obtained accuracy. All three of the networks outperform the state of the art for
two class weather classification with CloudyNet-P predicting the most accurately.

\figref{sort} shows the average errors from TransientNet-S for each attribute
in a sorted graph.  The attributes where TransientNet-S performed best are towards
the bottom of the graph and the attributes where TransientNet-S performed
worst are on the top of the graph. \figref{relerr} and \figref{compare} 
compare this performance to the performance of Laffont et al.

\figref{compare} shows the average errors from TransientNet-S, TransientNet-P, 
TransientNet-H and Laffont et al. for each attribute in the dataset.  The green bars 
represent the average errors from Laffont et al., the blue bars represent the average 
errors from TransientNet-S, the red bars represent the average errors from TransientNet-P, 
and the yellow bars represent the error from TransientNet-H. TransientNet-S performs best on 
more than half of the attributes and is the best performing CNN that we trained.  
Transient has the lowest overall average error as shown in \tblref{transient}.  TransientNet-P
and TransientNet-H have similar performance, mostly due to them being pretrained on similar 
sets of data.

\figref{relerr} shows the relative error between our method using TransientNet-S
and the method presented in \cite{Laffont14}.  The average relative error 
for each attribute using the method in \cite{Laffont14} was subtracted from
the average relative error using TransientNet-S.  A negative value means TransientNet-S
had a smaller error and a positive value means \cite{Laffont14} had a smaller
error.  For example, the difference between the two methods on the attribute
night was around 3.2 percentage points, with TransientNet-S having the smaller 
error.

 
%Suggested plots:
%\begin{itemize}
%
%  \item summary results you have already shown
%
%  \item example good results, and plausible bad results
%
%\end{itemize}

\begin{table}[t]
	\centering
	\begin{tabular}{ | l | c | }
		\hline
			Method & Normalized Accuracy \\ \hline
			Lu et al. \cite{lutwoclass}& 53.1\% \\ \hline
			CloudyNet-S & 80.2\% \\ \hline
			CloudyNet-P & \textbf{83.3\%} \\ \hline
			CloudyNet-H & 82.2\% \\ 
		\hline
	\end{tabular}
	\caption{Two Class Weather Classification Accuracy}
	\label{tbl:twoclass}
\end{table}

\begin{figure}[t]
	\centering
		\includegraphics[width=0.5\textwidth]{figs/sorted_err_cmr.pdf}
		\caption{This shows the average errors in TransientNet-S's predictions on the 
						 testing set sorted from largest to smallest.  The attributes at 
						 the top of the plot have the highest average error.}
		\label{fig:sort}
\end{figure}

\begin{figure}[t]
	\centering
		\includegraphics[width=0.5\textwidth]{figs/rel_err_cmr.pdf}
		\caption{This shows the relative errors of TransientNet-S against the method 
						 proposed by Laffont et al. for each attribute.  Attributes with a 
						 negative average error are attributes that are predicting more 
						 accurately by our method.}
		\label{fig:relerr}
\end{figure}

\begin{figure*}[t]
	\centering
		\includegraphics[width=1.0\textwidth]{figs/avg_err_compare_cmr.pdf}
		\caption{This shows the average errors for each attribute from proposed method
						 by Laffont et al., TransientNet-S, TransientNet-P, and TransientNet-H.  
             TransientNet-S has the lowest average error for most of the attributes.}
		\label{fig:compare}
\end{figure*}

\begin{table}[t]
	\centering
	\begin{tabular}{ | l | c | }
		\hline
			Method & Average Error \\ \hline
			Laffont et al. \cite{Laffont14}& 8.48\% \\ \hline
			TransientNet-S & \textbf{7.65\%} \\ \hline
			TransientNet-P & 8.02\% \\ \hline
			TransientNet-H & 8.13\% \\ 
		\hline
	\end{tabular}
	\caption{Two Class Weather Classification Accuracy}
	\label{tbl:transient}
\end{table}

\section{Applications}
\todo{Think of more applications, expand on current one}
\subsection{Automatic Webcam Image Labeling}

\begin{itemize}

	\item Automatically label saved images from webcams
	\item Tag each image individually and be able to search for times from
			  webcam that had or did not have a certain attribute
	\item Tag frequent attributes for webcams (that aren't day/night)
	\item Makes AMOS or other webcam/image archives more searchable

\end{itemize}

% need another subsection

\section{Conclusions}
\todo{write me}

We evaluated the use of deep convolutional neural networks for predicting
transient attributes and classifying images in two class weather 
classification.  These networks achieve state of the art results on two
benchmark datasets.  The networks are simple to train and predict 
quickly.  The networks can quickly be retrained on additional datasets
and restructured.


\bibliographystyle{IEEEbib}
\bibliography{refs}

\end{document}

